{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd09fa-92bf-4de5-94bd-685739182d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def writeFilesToCSV(pathName):\n",
    "\n",
    "    allTopStories = []\n",
    "    totalFiles = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(pathName):\n",
    "       \n",
    "        if '2020/April' in dirpath:\n",
    "            for fN in filenames: \n",
    "                if fN.endswith('.json'): \n",
    "                    totalFiles += 1\n",
    "                    filePath = os.path.join(dirpath, fN)\n",
    "                    with open(filePath) as inputF:\n",
    "                        data = json.load(inputF)\n",
    "                        allTopStories.extend(data)\n",
    "                \n",
    "    print(\"Total number of JSON files in April 2020:\", totalFiles)\n",
    "    print(\"Total number of Top stories in April 2020:\", len(allTopStories))\n",
    "\n",
    "    with open(\"our-results.csv\", \"w\") as fout:\n",
    "        header = list(allTopStories[0].keys()) + ['category'] \n",
    "        dW = csv.DictWriter(fout, fieldnames=header)\n",
    "        dW.writeheader()\n",
    "        dW.writerows(allTopStories)\n",
    "\n",
    "\n",
    "writeFilesToCSV('GoogleTopStories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e55458-823e-4c46-b36f-01677578716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for our folder\n",
    "writeFilesToCSV('GoogleTopStories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d22530-4dc1-4ef1-87e8-690643bd2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('our-results.csv')\n",
    "df.head()\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "oneUrl = df.iloc[0]['url'] # retrieve url from first row of dataframe\n",
    "urlparse(oneUrl)\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def getDomain(field):\n",
    "    \"\"\"returns the domain name of a url\"\"\"\n",
    "    return urlparse(field).netloc\n",
    "df['domain2'] = df['url'].apply(getDomain)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6253c8-4058-4b5c-b754-4879138deffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('our-results.csv')\n",
    "\n",
    "# Create the 'wordCount' column\n",
    "df['wordCount'] = df['title'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Display the head of the DataFrame to show the new column\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ab29a-3eca-4ab5-b108-74c0b4891235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 domains using value_counts\n",
    "domainCounts = df['domain'].value_counts()[:10]\n",
    "type(domainCounts)\n",
    "data = domainCounts.reset_index(name='count')\n",
    "data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))   # adjusting the size of the figure where the plot will be displayed\n",
    "sns.set_style(\"whitegrid\")  \n",
    "\n",
    "# Create the horizontal bar plot\n",
    "ax = sns.barplot(x='count', y='domain', data=data, color=\"salmon\", legend=None)\n",
    "\n",
    "# Set titles\n",
    "ax.set_xlabel(\"Count\", fontsize=10)\n",
    "ax.set_ylabel(\"Domain\", fontsize=10)\n",
    "ax.set_title(\"Top 10 Domains by Count\", fontsize=14)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e04c2e-8736-46a5-bfee-61105efe0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('our-results.csv')\n",
    "\n",
    "# Create the 'wordCount' column\n",
    "df['wordCount'] = df['title'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Find the top 10 word counts\n",
    "wordCountTop10 = df['wordCount'].value_counts()[:10]\n",
    "data = wordCountTop10.reset_index(name='count')\n",
    "data = data.rename(columns={'index': 'wordCount'})\n",
    "\n",
    "plt.figure(figsize=(8, 4))   # Adjusting the size of the figure where the plot will be displayed\n",
    "sns.set_style(\"whitegrid\")   # Setting the style of the plot\n",
    "\n",
    "# Create the horizontal bar plot\n",
    "ax = sns.barplot(x='count', y='wordCount', data=data, color=\"skyblue\", orient='h')\n",
    "\n",
    "# Set titles\n",
    "ax.set_xlabel(\"Count\", fontsize=10)\n",
    "ax.set_ylabel(\"Word Count\", fontsize=10)\n",
    "ax.set_title(\"Top 10 Word Counts in Titles\", fontsize=14)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ed8b7-a5a4-4a53-a65e-4cc83d836ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topTen = df['domain'].value_counts()[:10].index.tolist() # remember from part 3 that value_counts returns a Series and the 'domain' column is the index of it\n",
    "dfSmall = df[df['domain'].isin(topTen)] # do the filtering. Notice the filter syntax.\n",
    "dfSmall.shape\n",
    "df.shape\n",
    "proportion = dfSmall.shape[0]/df.shape[0] * 100\n",
    "proportion\n",
    "\n",
    "it tells us that Goggles algorithms prioritize content the top domains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba67d5-d31f-41ce-a226-affbebd95847",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = dfSmall[['domain', 'story_position']] # work with a two-column dataframe\n",
    "\n",
    "pivotDF = dfFinal.pivot_table(index='domain', columns='story_position', \n",
    "                              aggfunc='size',fill_value=0)\n",
    "pivotDF.head(10)\n",
    "normalized = pivotDF.div(pivotDF.sum(axis=1), # first generate the sum of values in each row\n",
    "                         axis=0) # then divide all cells in a colum, by the corresponding sum\n",
    "normalized\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.set(font_scale=1.2)  # Adjust font size\n",
    "sns.heatmap(normalized, \n",
    "            cmap='BuGn', # set color map Blue to Green\n",
    "            annot=False, # do not show the numerical values in each cell\n",
    "            linewidths=0.5) # width of lines that separate the cells in the map\n",
    "\n",
    "# We are directly setting the properties of the current axes, without explicitely referring to it as we did in the barplot image\n",
    "plt.xlabel('Story position', fontsize=10)\n",
    "plt.ylabel('Domain', fontsize=10)\n",
    "plt.title('Proportion of Top 10 Domains by Position', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af318126-b3f8-446a-9f74-624fbe4356ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "I would say we would see a uniform distribution of colors \n",
    "Googles algorithm favor domains of certain posotions basedon factors of relevance \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
