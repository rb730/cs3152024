{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d36ea1-359b-45c8-b4bd-718103c21ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc44cf66-642f-4a83-b4b1-91751d69e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow tensorflow_hub scikit-learn seaborn plotly nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d947e59-06f7-4ded-bc61-465d155e2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f652e67-07fe-4c28-a9d4-173b3fcae628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c0c9f-423a-432f-bf5d-45943a25ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b88bf8-961d-426c-a2d1-c70840f887b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the word embedding of a single word\n",
    "embed([\"apple\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583587e-e984-414b-9bee-1a933b9c5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['king', 'queen', 'radio', 'TV', 'bike', 'car', 'Boston', 'London', 'lake', 'river']\n",
    "\n",
    "embeddings = embed(words)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76765c-fad0-4f1e-893f-afaece8d0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cosineSimilarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    V1 = np.array(vec1)\n",
    "    V2 = np.array(vec2)\n",
    "    cosine = np.dot(V1, V2)/(norm(V1)*norm(V2))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf005e2-50f8-43c9-bbb0-e2add83f7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseSimilarity(embeddings):\n",
    "    \"\"\"Given a matrix of embeddings for words or sentences,\n",
    "    calculate the cosine similarity for each pair.\n",
    "    \"\"\"\n",
    "    simMatrix = []\n",
    "    for vec1 in embeddings:\n",
    "        simRow = []\n",
    "        for vec2 in embeddings:\n",
    "            simRow.append(cosineSimilarity(vec1, vec2))\n",
    "        simMatrix.append(simRow)\n",
    "    return simMatrix\n",
    "    \n",
    "simMatrix = pairwiseSimilarity(embeddings)\n",
    "print(simMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d04325-078b-45f8-9f15-8e2f9d144880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def drawHeatmap(labels, simMtrx, plotTitle):\n",
    "    \"\"\"Draws a heatmap for the similarity matrix.\n",
    "    \"\"\"\n",
    "    sns.set(font_scale=0.9)\n",
    "    g = sns.heatmap(\n",
    "          simMtrx, # similarity matrix with the cosine sim values\n",
    "          xticklabels=labels,\n",
    "          yticklabels=labels,\n",
    "          vmin=0,\n",
    "          vmax=1,\n",
    "          cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=90)\n",
    "    g.set_title(plotTitle, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093ab83-2edd-4d6a-8e63-f0f6b428b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawHeatmap(words, simMatrix, \"Similarity for Word Embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcb39f-735b-4a8f-81bf-4d55a01cfb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f69a7-f0bf-40a4-9e8c-3955ff2f9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbowMethod(embeddings, maxK):\n",
    "    \"\"\"\n",
    "    Implements the Elbow method for finding most optimal k.\n",
    "    It keeps track of a measure named \"inertia\" for each cluster.\n",
    "    \"\"\"\n",
    "    sumSquaredDistances = []\n",
    "    kValues = list(range(1, maxK))\n",
    "    for k in kValues:\n",
    "        km = KMeans(n_clusters=k, random_state=42)\n",
    "        km = km.fit(embeddings)\n",
    "        sumSquaredDistances.append(km.inertia_)\n",
    "    \n",
    "    # plot the line to identify the elbow\n",
    "    plt.plot(kValues, sumSquaredDistances, 'ro-')\n",
    "    plt.xlabel('k')\n",
    "    plt.xticks(kValues)\n",
    "    plt.ylabel('Sum of squared distances')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5799f-a365-4669-97c7-7850770cf60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elbowMethod(newsEmbed, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c6353-d4c5-4c11-8a1c-abdfdcdf2943",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(newsEmbed)\n",
    "\n",
    "clusters[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f668e0-7f93-4a0d-b6d0-08f97b24fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1ca9d-faa7-41db-ad41-a0fb40eb6c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa44ed7-a313-4655-8286-8a87048bc0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)  \n",
    "tsne_results = tsne.fit_transform(newsEmbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67f7de-5f9e-4939-bf7f-70ba81cd6853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(tsne_results, columns=['tsne_1', 'tsne_2'])\n",
    "df['hashtag'] = news  \n",
    "df['cluster'] = clusters # the cluster indices where each news hashtags belong\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a2cb31-363f-441a-8a75-b98c72d9be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create the scatter plot\n",
    "fig = px.scatter(df, x='tsne_1', y='tsne_2', text='hashtag', color=\"cluster\", color_continuous_scale=\"BlueRed\")\n",
    "\n",
    "# Format what to show next to the markers\n",
    "fig.update_traces(textposition='top center', \n",
    "                  mode='markers+text', \n",
    "                  textfont=dict(size=6))\n",
    "\n",
    "fig.update_layout(title='Embeddings of TikTok News Hashtags', width=800, height=800)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a1bbc-33cb-4ab5-b0fc-8d926e3b9c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
